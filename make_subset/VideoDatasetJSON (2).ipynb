{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076f002-b000-476c-8588-883110174348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731935d4-27f6-4a98-83d7-ee02abaf7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def read_and_show_json(file_path,signs,output_path):\n",
    "#     output=\"{\"\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             json_content = json.load(file)\n",
    "#             for key, value in json_content.items():\n",
    "#                 if json.dumps(value[\"action\"][0]) in signs:\n",
    "#                     output+= '\"'+key+'\": '+json.dumps(value)+', '\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File not found: {file_path}\")\n",
    "        \n",
    "#     out = output[:-2]+\"}\"\n",
    "\n",
    "#     f = open(output_path, \"w\")\n",
    "#     f.write(out)\n",
    "#     f.close()\n",
    "\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf000ba-551c-4e91-a176-688d1b5366d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file_path = 'nslt_100.json'\n",
    "# output_path = 'nslt_selected.json'\n",
    "# signs = [\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\"]\n",
    "\n",
    "# out = read_and_show_json(json_file_path,signs,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ae260-cb7f-4d2c-9a21-8a8b21bf8537",
   "metadata": {},
   "source": [
    "# New tasks to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c50f49-2a37-4751-99b4-5478f9f241dc",
   "metadata": {},
   "source": [
    "\"06335\": {\"subset\": \"test\", \"action\": [53, 1, 94]}\n",
    "\n",
    "\"Video ID\": {\"subset\": \"test/train/val\", \"action\": [wordID, num1, num2]}\n",
    "\n",
    "Word Id needs to start at 0\n",
    "\n",
    "count how many videos per word\n",
    "\n",
    "split the dataset:\n",
    "    train/set [70/30]\n",
    "    train/set/val [60/20/20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4046f-46fd-4aee-a5c0-7cbed57cbb71",
   "metadata": {},
   "source": [
    "## Counting train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457195bd-08f9-4316-9279-65638c443688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def countPercent(file_path):\n",
    "    sets = np.array([\"train\",\"test\",\"val\"])\n",
    "    countSets = np.array([0,0,0])\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():\n",
    "                sample = json.dumps(value[\"subset\"])[1:-1]\n",
    "                i = np.where(sets == sample)\n",
    "                countSets[i]+=1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    return countSets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df45c230-d7c6-455f-98bb-88e7d4f2fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of sets [train, test, val]\n",
      "[1442  258  338]\n",
      "\n",
      "Percentages\n",
      "train: 70.7556\n",
      "test: 12.6595\n",
      "val: 16.5849\n",
      "\n",
      "Total: 100.00\n"
     ]
    }
   ],
   "source": [
    "json_file_path = '../wlasl-complete/nslt_100.json'\n",
    "\n",
    "sets = countPercent(json_file_path)\n",
    "print(\"count of sets [train, test, val]\")\n",
    "print(sets)\n",
    "print(\"\\nPercentages\")\n",
    "print(\"train: %.4f\"%(sets[0]/sum(sets)*100))\n",
    "print(\"test: %.4f\"%(sets[1]/sum(sets)*100))\n",
    "print(\"val: %.4f\"%(sets[2]/sum(sets)*100))\n",
    "\n",
    "print(\"\\nTotal: %.2f\"%((sets[0]/sum(sets)+sets[1]/sum(sets)+sets[2]/sum(sets))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c5b58-55e8-41c3-b968-ecedf5542ae3",
   "metadata": {},
   "source": [
    "## Redefining Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548b4779-10bb-4b2f-bfc5-c6192daa1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVideos(file_path):\n",
    "    count = 1\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():\n",
    "                count+=1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101344c5-604a-48c4-b9e5-30efe6f50f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomArray(N, a, b, c): \n",
    "    total_elements = a + b + c\n",
    "    if total_elements != 100:\n",
    "        raise ValueError(\"Percentages should add up to 100.\")\n",
    "    array = [\"train\"] * (N * a // 100) + [\"test\"] * (N * b // 100) + [\"val\"] * (N * c // 100)\n",
    "    random.shuffle(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5c4fca-37d9-4a1c-8d05-19108ffa366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSets(file_path):\n",
    "    sets = np.array([\"train\",\"test\",\"val\"])\n",
    "    countSets = np.array([0,0,0])\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():\n",
    "                sample = json.dumps(value[\"subset\"])[1:-1]\n",
    "                print(sample)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    return countSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0fd6d1-e5c9-4e26-a2bc-b32faf1ae895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def redefineSets(test, val, file_path, output_path):\n",
    "    ids = getVideoIDs(file_path)\n",
    "    train = 100 - (test+val)\n",
    "    N = countVideos(file_path)\n",
    "    randSets = randomArray(N, train, test, val)\n",
    "    count = 0\n",
    "    output=\"{\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():  \n",
    "                #str(ids.index(value[\"action\"][0]))\n",
    "                newValue = '\"'+key+'\": {\"subset\": \"'+ randSets[count] + '\", \"action\": ['+str(ids.index(value[\"action\"][0])) +', '+str(value[\"action\"][1])+', '+str(value[\"action\"][2])+']}, '\n",
    "                count+=1\n",
    "                output += newValue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    out = output[:-2]+\"}\"\n",
    "\n",
    "    f = open(output_path, \"w\")\n",
    "    f.write(out)\n",
    "    f.close()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718dfd53-0789-43fd-a78f-fa834ead2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoIDs(file_path):\n",
    "    ids=[]\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():             \n",
    "                if value[\"action\"][0] not in ids:\n",
    "                    ids.append(value[\"action\"][0])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        \n",
    "    ids.sort()\n",
    "    return ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c203228d-b3a0-40db-8446-55619de4d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "json_file_path = 'nslt_selected.json'\n",
    "ids = getVideoIDs(json_file_path)\n",
    "print(ids)\n",
    "\n",
    "pos = ids.index(55)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bb0e6e-da6a-4be5-9f1b-cd14abc95c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of sets [train, test, val]\n",
      "[115  38  38]\n",
      "\n",
      "Percentages\n",
      "train: 60.2094\n",
      "test: 19.8953\n",
      "val: 19.8953\n",
      "\n",
      "Total: 100.00\n"
     ]
    }
   ],
   "source": [
    "# json_file_path = 'nslt_selected.json'\n",
    "json_file_path = 'nslt_selected.json'\n",
    "json_output_path = 'nslt_ajusted.json'\n",
    "test = 20\n",
    "val = 20\n",
    "# train will be 100 - (test + val)\n",
    "out = redefineSets(test,val, json_file_path,json_output_path)\n",
    "#print(out)\n",
    "\n",
    "# checking the new set definitions\n",
    "sets = countPercent(json_output_path)\n",
    "print(\"count of sets [train, test, val]\")\n",
    "print(sets)\n",
    "print(\"\\nPercentages\")\n",
    "print(\"train: %.4f\"%(sets[0]/sum(sets)*100))\n",
    "print(\"test: %.4f\"%(sets[1]/sum(sets)*100))\n",
    "print(\"val: %.4f\"%(sets[2]/sum(sets)*100))\n",
    "\n",
    "print(\"\\nTotal: %.2f\"%((sets[0]/sum(sets)+sets[1]/sum(sets)+sets[2]/sum(sets))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af695b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of sets [train, test, val]\n",
      "[109  28  26]\n",
      "\n",
      "Percentages\n",
      "train: 66.8712\n",
      "test: 17.1779\n",
      "val: 15.9509\n",
      "\n",
      "Total: 100.00\n"
     ]
    }
   ],
   "source": [
    "# count percents only\n",
    "\n",
    "json_output_path = 'nslt_ajusted.json'\n",
    "\n",
    "sets = countPercent(json_output_path)\n",
    "print(\"count of sets [train, test, val]\")\n",
    "print(sets)\n",
    "print(\"\\nPercentages\")\n",
    "print(\"train: %.4f\"%(sets[0]/sum(sets)*100))\n",
    "print(\"test: %.4f\"%(sets[1]/sum(sets)*100))\n",
    "print(\"val: %.4f\"%(sets[2]/sum(sets)*100))\n",
    "\n",
    "print(\"\\nTotal: %.2f\"%((sets[0]/sum(sets)+sets[1]/sum(sets)+sets[2]/sum(sets))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278498b4-48bc-46dd-bae3-5873bb3d55f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of sets [train, test, val]\n",
      "[109  28  26]\n",
      "\n",
      "Percentages\n",
      "train: 66.8712\n",
      "test: 17.1779\n",
      "val: 15.9509\n",
      "\n",
      "Total: 100.00\n"
     ]
    }
   ],
   "source": [
    "# count percents only\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def countPercent(file_path):\n",
    "    sets = np.array([\"train\",\"test\",\"val\"])\n",
    "    countSets = np.array([0,0,0])\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "            for key, value in json_content.items():\n",
    "                sample = json.dumps(value[\"subset\"])[1:-1]\n",
    "                i = np.where(sets == sample)\n",
    "                countSets[i]+=1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    return countSets\n",
    "\n",
    "\n",
    "json_output_path = '../code/i3d/preprocess/nslt_10_01.json'\n",
    "\n",
    "sets = countPercent(json_output_path)\n",
    "print(\"count of sets [train, test, val]\")\n",
    "print(sets)\n",
    "print(\"\\nPercentages\")\n",
    "print(\"train: %.4f\"%(sets[0]/sum(sets)*100))\n",
    "print(\"test: %.4f\"%(sets[1]/sum(sets)*100))\n",
    "print(\"val: %.4f\"%(sets[2]/sum(sets)*100))\n",
    "\n",
    "print(\"\\nTotal: %.2f\"%((sets[0]/sum(sets)+sets[1]/sum(sets)+sets[2]/sum(sets))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
